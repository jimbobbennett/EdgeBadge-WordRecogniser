{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure training\n",
    "\n",
    "The following os.environ lines can be customized to set the words that will be trained for, and the steps and learning rate of the training. The default values will result in the same model that is used in the micro_speech example. Run the cell to set the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# A comma-delimited list of the words you want to train for.\n",
    "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
    "# All other words will be used to train an \"unknown\" category.\n",
    "os.environ[\"WANTED_WORDS\"] = \"zero,one,two,three,four,five,six,seven,eight,nine\"\n",
    "\n",
    "# The number of steps and learning rates can be specified as comma-separated\n",
    "# lists to define the rate at each stage. For example,\n",
    "# TRAINING_STEPS=15000,3000 and LEARNING_RATE=0.001,0.0001\n",
    "# will run 18,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 15,000, and 0.0001 for the final 3,000.\n",
    "os.environ[\"TRAINING_STEPS\"]=\"15000,3000\"\n",
    "os.environ[\"LEARNING_RATE\"]=\"0.001,0.0001\"\n",
    "\n",
    "# Calculate the total number of steps, which is used to identify the checkpoint\n",
    "# file name.\n",
    "total_steps = sum(map(lambda string: int(string),\n",
    "                  os.environ[\"TRAINING_STEPS\"].split(\",\")))\n",
    "os.environ[\"TOTAL_STEPS\"] = str(total_steps)\n",
    "\n",
    "# Print the configuration to confirm it\n",
    "!echo \"Training these words: ${WANTED_WORDS}\"\n",
    "!echo \"Training steps in each stage: ${TRAINING_STEPS}\"\n",
    "!echo \"Learning rate in each stage: ${LEARNING_RATE}\"\n",
    "!echo \"Total number of training steps: ${TOTAL_STEPS}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "Next, we'll install a GPU build of TensorFlow, so we can use GPU acceleration for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow-gpu tensorflow tensorflow_estimator tensorboard\n",
    "!pip install -q tensorflow-estimator==1.15.1 tensorflow-gpu==1.15.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also clone the TensorFlow repository, which contains the scripts that train and freeze the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository from GitHub\n",
    "!git clone -q https://github.com/tensorflow/tensorflow /mnt/tmp/tensorflow\n",
    "# Check out a commit that has been tested to work\n",
    "# with the build of TensorFlow we're using\n",
    "!git -c advice.detachedHead=false -C /mnt/tmp/tensorflow checkout 17ce384df70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training\n",
    "Next, run the following script to begin training. The script will first download the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /mnt/tmp/tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
    "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
    "--wanted_words=${WANTED_WORDS} --silence_percentage=25 --unknown_percentage=25 \\\n",
    "--quantize=1 --verbosity=WARN --how_many_training_steps=${TRAINING_STEPS} \\\n",
    "--learning_rate=${LEARNING_RATE} --summaries_dir=/mnt/tmp/content/retrain_logs \\\n",
    "--data_dir=/mnt/tmp/content/speech_dataset --train_dir=/mnt/tmp/content/speech_commands_train \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training finished\n",
    "\n",
    "Export the model in a compact format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /mnt/tmp/tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n",
    "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
    "--wanted_words=${WANTED_WORDS} --quantize=1 --output_file=./content/tiny_conv.pb \\\n",
    "--start_checkpoint=/mnt/tmp/content/speech_commands_train/tiny_conv.ckpt-${TOTAL_STEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model\n",
    "\n",
    "Run this cell to use the TensorFlow Lite converter to convert the frozen graph into the TensorFlow Lite format, fully quantized for use with embedded devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!toco \\\n",
    "--graph_def_file=./content/tiny_conv.pb --output_file=./content/tiny_conv.tflite \\\n",
    "--input_shapes=1,49,40,1 --input_arrays=Reshape_2 --output_arrays='labels_softmax' \\\n",
    "--inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_size = os.path.getsize(\"./content/tiny_conv.tflite\")\n",
    "print(\"Model is %d bytes\" % model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use xxd to transform the model into a source file that can be included in a C++ project and loaded by TensorFlow Lite for Microcontrollers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file as a C source file\n",
    "!xxd -i ./content/tiny_conv.tflite > ./content/tiny_conv.cc\n",
    "# Print the source file\n",
    "!cat ./content/tiny_conv.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
